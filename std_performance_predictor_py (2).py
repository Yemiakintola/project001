# -*- coding: utf-8 -*-
"""std_performance_predictor.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OkLJGjoSF-gQiOPTFhz1eFz1YiDrvrDv

**STUDENTS PERFORMANCE PREDICTOR**

Project Goal:

The main goal of this project is to develop a predictive model for student performance, specifically focusing on GPA. This is evident from the data loading, exploration, and modeling steps centered around the 'GPA' variable.

Justifications:

Understanding Factors Influencing Student Performance: The project aims to identify and understand the key factors that influence student performance. By analyzing the dataset and building predictive models, insights can be gained into the relationship between various features (e.g., study time, absences, parental education) and GPA. This information is valuable for educators and policymakers to make informed decisions to improve student outcomes.

Predictive Capability: The project aims to develop a model that can accurately predict student GPA based on their characteristics and behaviors. This predictive capability can be used for early identification of students who might be at risk of academic difficulties, allowing for timely intervention and support. It can also assist in personalized learning approaches by tailoring educational resources and strategies based on individual student predictions.

Data-Driven Decision Making: The project emphasizes a data-driven approach to understanding and improving student performance. By using statistical analysis, machine learning techniques, and data visualization, the project provides evidence-based insights for educators and stakeholders to make informed decisions about educational strategies and policies.

Continuous Improvement: The project encourages ongoing evaluation and refinement of the predictive models. By monitoring model performance and incorporating new data, the project can be adapted to changing student populations and educational environments. This iterative approach ensures the models remain relevant and effective over time.

Evidence from the Code:

Data Exploration: The code includes extensive data exploration steps, including descriptive statistics, distributions, and relationships between features, to gain an initial understanding of the data and identify potential predictors of GPA.
Feature Engineering: The creation of interaction and polynomial features demonstrates an effort to improve model accuracy by capturing complex relationships between variables.
Model Training and Optimization: The use of multiple regression models and hyperparameter optimization techniques reflects a rigorous approach to building the best possible predictive model.
Model Evaluation: The evaluation of models on the test set using metrics like MSE and R2 score ensures the model's generalizability and predictive accuracy.

Import the neccessary libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
import numpy as np

"""Read the dataset into pandas"""

df = pd.read_csv('/content/Student_performance_data _.csv')

"""Peep into the data"""

display(df.head(50))
print(df.shape)

"""Explore the data for better undertanding with some histogram plots showing the distribution of student performance scores"""

# Data types and descriptive statistics
print(df.info())
print(df.describe())

# Distributions of student performance scores
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
sns.histplot(df['GPA'], kde=True)
plt.title('Distribution of GPA')

plt.subplot(1, 3, 2)
sns.histplot(df['StudyTimeWeekly'], kde=True)
plt.title('Distribution of Study Time')

plt.subplot(1, 3, 3)
sns.histplot(df['Absences'], kde=True)
plt.title('Distribution of Absences')

plt.tight_layout()
plt.show()

# Relationships between performance and other features
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
sns.boxplot(x='Gender', y='GPA', data=df)
plt.title('GPA vs. Gender')

plt.subplot(1, 3, 2)
sns.boxplot(x='ParentalEducation', y='GPA', data=df)
plt.title('GPA vs. Parental Education')

plt.subplot(1, 3, 3)
sns.scatterplot(x='StudyTimeWeekly', y='GPA', data=df)
plt.title('GPA vs. Study Time')

plt.tight_layout()
plt.show()


# Identify potential outliers
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
sns.boxplot(y=df['GPA'])
plt.title('Outliers in GPA')

plt.subplot(1, 3, 2)
sns.boxplot(y=df['StudyTimeWeekly'])
plt.title('Outliers in Study Time')

plt.subplot(1, 3, 3)
sns.boxplot(y=df['Absences'])
plt.title('Outliers in Absences')

plt.tight_layout()
plt.show()

"""Data cleaning: Identify missing values, handle outliers seen in the boxplots and check for inconsistences in the categorical columns"""

# Identify missing values
print(df.isnull().sum())

# Handle outliers in 'GPA', 'StudyTimeWeekly', and 'Absences' using winsorizing
for col in ['GPA', 'StudyTimeWeekly', 'Absences']:
    q1 = df[col].quantile(0.25)
    q3 = df[col].quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)

# Check for inconsistencies in categorical features
for col in ['Gender', 'Ethnicity', 'ParentalEducation', 'Tutoring', 'ParentalSupport', 'Extracurricular', 'Sports', 'Music', 'Volunteering', 'GradeClass']:
    print(f"Unique values for {col}: {df[col].unique()}")
    # Further inspection may be needed to handle inconsistencies based on the observed unique values

# Verify the cleaning steps
print(df.isnull().sum())
print(df.describe())
display(df.head())

"""Verify the cleaning measure taken"""

# Further inspection of categorical features and handling inconsistencies
# GradeClass: 0 seems out of range.
df['GradeClass'] = df['GradeClass'].replace(0, df['GradeClass'].mode()[0])

# Verify the changes again
print(df.isnull().sum())
print(df.describe())
display(df.head())

import pandas as pd
import numpy as np
import joblib # Import joblib

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, PolynomialFeatures, FunctionTransformer # Import necessary transformers
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score # Import evaluation metrics
from google.colab import files # Import files for downloading


# --- Define Features and Target ---
# Define the columns that will be the INITIAL input features (X)
categorical_binary = ['Gender', 'Tutoring', 'Extracurricular', 'Sports', 'Music', 'Volunteering']
categorical_multi = ['Ethnicity', 'ParentalEducation', 'ParentalSupport', 'GradeClass']
numerical_cols = ['Age', 'StudyTimeWeekly', 'Absences'] # Numerical features used as input

target = 'GPA' # The target variable (y)

# --- Create Feature Matrix (X) and Target Vector (y) ---
X = df[categorical_binary + categorical_multi + numerical_cols]
y = df[target]

print("Initial features (X) and target (y) defined.")
print("X shape:", X.shape)
print("y shape:", y.shape)


# --- Define Preprocessing Steps (within the pipeline) ---

# Preprocessing for binary categorical columns
# Using 'error' is safer for ensuring data consistency
binary_transformer = OrdinalEncoder(handle_unknown='error')

# Preprocessing for multi-class categorical columns
# 'ignore' is suitable here to handle potential unseen categories gracefully during prediction
multi_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)

# Preprocessing for numerical columns
numerical_transformer = StandardScaler()

# Combine initial preprocessing into a ColumnTransformer
# This applies transformations column-wise to the initial features
preprocessor = ColumnTransformer(
    transformers=[
        ("binary", binary_transformer, categorical_binary),
        ("multi", multi_transformer, categorical_multi),
        ("num", numerical_transformer, numerical_cols),
    ],
    remainder='passthrough' # Keep any columns not explicitly transformed (should be none here)
)

# --- Define Feature Engineering Step (within the pipeline) ---
# This step will be applied AFTER the initial preprocessing by the ColumnTransformer.
# We can create polynomial features or interaction terms ONLY from the columns output by the preprocessor.
# Since the output of the preprocessor is a numpy array, we need to be careful with column indices.
# A simpler way might be to apply PolynomialFeatures directly to the numerical columns *after* scaling,
# and potentially create interactions between scaled numerical and encoded categorical features.

# Let's add polynomial features for numerical columns as an example.
# This needs to operate on the numerical columns *after* scaling.
# This requires accessing specific columns from the output of the ColumnTransformer.

# A common pattern is to use a 'named_steps' approach or a subsequent transformer.
# Let's use a function transformer to demonstrate, though PolynomialFeatures is a built-in option.

# Function to add polynomial features for numerical columns
# This function needs to know which columns in the *output* of the preprocessor correspond to the numerical features.
# This is tricky with ColumnTransformer's numpy output.

# **Alternative: Separate Feature Engineering and use ColumnTransformer Twice or a custom transformer**
# A more robust way is to define a transformer that handles engineering after initial preprocessing.

# Let's simplify and add only polynomial features for the scaled numerical columns within the pipeline.
# This requires knowing the indices of the numerical columns *after* the ColumnTransformer.
# This is complex and error-prone if column order changes.

# **Best Practice within Pipeline:**
# Often, simple polynomial or interaction features involving numerical columns are done directly using `PolynomialFeatures`
# applied to the numerical columns within the `ColumnTransformer` or as a separate step after it.
# Interactions between numerical and categorical columns require careful handling after encoding.

# Let's add a PolynomialFeatures transformer specifically for the original numerical columns.
# This can be done within the ColumnTransformer itself, targeting those specific columns,
# or as a step *after* the ColumnTransformer, operating on the relevant output columns.
# Applying PolynomialFeatures *after* scaling the numerical columns is common.

# We need to identify the indices of the numerical columns in the output of the preprocessor.
# The order in ColumnTransformer is: binary, multi, num.
# The output shape is (n_samples, n_binary + n_multi_encoded + n_numerical).
# The numerical columns will be the LAST ones in the output.

# Let's find the indices:
num_binary = len(categorical_binary)
num_multi_encoded_example = len(df[categorical_multi[0]].unique()) -1 + (len(categorical_multi)-1) # Estimate, actual depends on OHE
num_initial_numerical = len(numerical_cols) # This is the count we care about for PolynomialFeatures

# The numerical columns will start at index `num_binary + total_encoded_multi_columns`.
# Getting the exact `total_encoded_multi_columns` from OHE in CT is non-trivial before fitting.

# **Simpler Alternative for Feature Engineering within Pipeline:**
# Create a FunctionTransformer that operates on the *initial* DataFrame X *before* the ColumnTransformer.
# This function would add polynomial/interaction features that *only* use columns from X.

def create_input_engineered_features(X):
    X_eng = X.copy()
    # Example: Add polynomial features for Age and StudyTimeWeekly, and interaction between them
    if 'Age' in X_eng.columns:
        X_eng['Age_Squared'] = X_eng['Age'] ** 2
    if 'StudyTimeWeekly' in X_eng.columns:
         X_eng['StudyTimeWeekly_Squared'] = X_eng['StudyTimeWeekly'] ** 2
    if 'Age' in X_eng.columns and 'StudyTimeWeekly' in X_eng.columns:
        X_eng['Age_StudyTime_Interaction'] = X_eng['Age'] * X_eng['StudyTimeWeekly']

    # You can add other interaction terms between numerical and potentially encoded categorical features here
    # but operating on pandas columns before CT is easier.
    return X_eng

# Transformer to apply the function
feature_engineer = FunctionTransformer(create_input_engineered_features, validate=False) # validate=False if output isn't numpy

# Now, the ColumnTransformer needs to handle the columns *output* by the FunctionTransformer.
# The FunctionTransformer adds new columns. The ColumnTransformer needs to know about ALL of them.
# This means we need to redefine the lists of columns passed to the ColumnTransformer *after* the FunctionTransformer step.

# **Revised Pipeline Structure: Feature Engineering FIRST (using only X)**

# Define the FunctionTransformer that adds features based only on initial X
def create_input_engineered_features_df(X):
    """Creates engineered features from the input DataFrame X."""
    X_eng = X.copy()
    # Add polynomial features for numerical columns
    for col in ['Age', 'StudyTimeWeekly', 'Absences']:
         if col in X_eng.columns:
              X_eng[f'{col}_Squared'] = X_eng[col] ** 2

    # Add interaction features between numerical columns
    if 'StudyTimeWeekly' in X_eng.columns and 'Absences' in X_eng.columns:
         X_eng['StudyTime_Absences_Interaction'] = X_eng['StudyTimeWeekly'] * X_eng['Absences']
    if 'Age' in X_eng.columns and 'StudyTimeWeekly' in X_eng.columns:
         X_eng['Age_StudyTime_Interaction'] = X_eng['Age'] * X_eng['StudyTimeWeekly']
    # Add other interactions as needed, using only columns from X

    # Example interaction between a numerical and a categorical (this is more complex to do here before encoding)
    # For simplicity in this example, we'll stick to interactions/polynomials of numerical features.
    # Interactions with categorical features are usually done *after* OneHotEncoding.

    return X_eng

# FunctionTransformer to apply the engineering
feature_engineer_transformer = FunctionTransformer(func=create_input_engineered_features_df, validate=False) # validate=False for DataFrame output

# Get the column names *after* feature engineering (requires a dummy run or knowing the function's output)
# Let's run it on a sample to see the columns
dummy_X = create_input_engineered_features_df(X.head(1))
engineered_feature_names = list(dummy_X.columns)

# Now, define the ColumnTransformer on the *engineered* feature names
# We need to categorize the *new* list of columns for the CT
# The original categorical columns are still binary or multi
categorical_binary_eng = [col for col in engineered_feature_names if col in categorical_binary]
categorical_multi_eng = [col for col in engineered_feature_names if col in categorical_multi]
# The numerical columns now include the original numerical + the new polynomial/interaction numerical ones
numerical_cols_eng = [col for col in engineered_feature_names if col not in categorical_binary_eng + categorical_multi_eng]


# Redefine the preprocessor to operate on the engineered features
preprocessor_eng = ColumnTransformer(
    transformers=[
        ("binary", OrdinalEncoder(handle_unknown='error'), categorical_binary_eng),
        ("multi", OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_multi_eng),
        ("num", StandardScaler(), numerical_cols_eng), # Scale ALL numerical columns (original and engineered)
    ],
    remainder='passthrough' # Keep any columns not explicitly transformed (should be none)
)


# --- Create the BEST OPTION Pipeline ---
# This pipeline first creates engineered features from X, then preprocesses ALL features, then trains the model.
best_option_pipeline = Pipeline(steps=[
    ("feature_engineer", feature_engineer_transformer), # Step 1: Create engineered features from X
    ("preprocessor", preprocessor_eng),             # Step 2: Preprocess all features (original + engineered)
    ("regressor", RandomForestRegressor(random_state=42)) # Step 3: The chosen model
])


# --- Split Data ---
# Split the initial X and y
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nInitial data split into training and testing sets.")
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)


# --- Train the BEST OPTION Pipeline ---
print("\nTraining the BEST OPTION Pipeline...")
# The pipeline's fit method will apply:
# 1. feature_engineer_transformer.transform(X_train) -> X_train_eng
# 2. preprocessor_eng.fit_transform(X_train_eng) -> X_train_processed
# 3. regressor.fit(X_train_processed, y_train)
best_option_pipeline.fit(X_train, y_train)
print("BEST OPTION Pipeline training complete.")


# --- Evaluate the Trained Pipeline (Optional but Recommended) ---
print("\nEvaluating the BEST OPTION Pipeline on the test set...")
# The pipeline's predict method will apply:
# 1. feature_engineer_transformer.transform(X_test) -> X_test_eng
# 2. preprocessor_eng.transform(X_test_eng) -> X_test_processed
# 3. regressor.predict(X_test_processed)
y_pred_test = best_option_pipeline.predict(X_test)
test_mse = mean_squared_error(y_test, y_pred_test)
test_r2 = r2_score(y_test, y_pred_test)

print(f"BEST OPTION Pipeline - Test MSE: {test_mse:.4f}")
print(f"BEST OPTION Pipeline - Test R2: {test_r2:.4f}")


# --- Save the Trained Pipeline ---
pipeline_filename_best = "best_student_performance_prediction_pipeline.pkl"
joblib.dump(best_option_pipeline, pipeline_filename_best)

print(f"\nâœ… BEST OPTION Trained pipeline saved as {pipeline_filename_best}")

# --- Make the .pkl file available for download ---
print(f"Making '{pipeline_filename_best}' available for download...")
try:
    files.download(pipeline_filename_best)
    print(f"'{pipeline_filename_best}' is ready for download.")
except Exception as e:
    print(f"Error during file download: {e}")

print("\n--- Summary of this Pipeline ---")
print("This pipeline includes:")
print("1. Feature Engineering (polynomials/interactions of input features)")
print("2. Preprocessing (Encoding & Scaling of original and engineered features)")
print("3. RandomForestRegressor model")
print("It is suitable for predicting GPA on new data by taking raw input features (X).")
preprocessor = ColumnTransformer(
    transformers=[
        ("binary", binary_transformer, categorical_binary),
        ("multi", multi_transformer, categorical_multi),
        ("num", numerical_transformer, numerical_cols),
    ],
    remainder='passthrough'
)

"""Identify categorical and numerical features, then encode categorical features using one-hot encoding for features with more than two unique values and label encoding for binary features. Finally, scale numerical features using standardization"""

# Identify categorical and numerical features
categorical_cols = ['Gender', 'Ethnicity', 'ParentalEducation', 'Tutoring', 'ParentalSupport', 'Extracurricular', 'Sports', 'Music', 'Volunteering', 'GradeClass']
numerical_cols = ['Age', 'StudyTimeWeekly', 'Absences', 'GPA']

# Encode categorical features
df_encoded = df.copy()
for col in categorical_cols:
    if len(df[col].unique()) > 2:
        # Use one-hot encoding for features with more than two unique values
        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
        encoded_data = ohe.fit_transform(df_encoded[[col]])
        encoded_df = pd.DataFrame(encoded_data, columns=ohe.get_feature_names_out([col]))
        df_encoded = pd.concat([df_encoded, encoded_df], axis=1).drop(col, axis=1)
    else:
        # Use label encoding for binary features
        le = LabelEncoder()
        df_encoded[col] = le.fit_transform(df_encoded[col])

# Scale numerical features
scaler = StandardScaler()
df_scaled = df_encoded.copy()
df_scaled[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])

# Combine encoded and scaled features
df_prepared = df_scaled

display(df_prepared.head())

""" Create interaction and polynomial features based on the existing features in df_prepared and add them as new columns to the dataframe."""

# Create interaction features
df_prepared['GPA_StudyTime_Interaction'] = df_prepared['GPA'] * df_prepared['StudyTimeWeekly']
df_prepared['GPA_Absences_Interaction'] = df_prepared['GPA'] * df_prepared['Absences']

# Create polynomial features
df_prepared['GPA_Squared'] = df_prepared['GPA'] ** 2
df_prepared['StudyTimeWeekly_Squared'] = df_prepared['StudyTimeWeekly'] ** 2

# Document the new features
print("New features added to df_prepared:")
print("- GPA_StudyTime_Interaction: Interaction between GPA and StudyTimeWeekly.")
print("- GPA_Absences_Interaction: Interaction between GPA and Absences.")
print("- GPA_Squared: Square of GPA.")
print("- StudyTimeWeekly_Squared: Square of StudyTimeWeekly.")

# Display first few rows to show the new features
display(df_prepared.head())

"""Split the data into training and testing sets using train_test_split"""

from sklearn.model_selection import train_test_split

# Define features (X) and target variables (y)
X = df_prepared.drop(['GPA'], axis=1)
y = df_prepared['GPA']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Print shapes of the resulting sets
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

"""Train multiple regression models on the training data"""

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Initialize models
linear_reg = LinearRegression()
tree_reg = DecisionTreeRegressor()
forest_reg = RandomForestRegressor()

# Train models
linear_reg.fit(X_train, y_train)
tree_reg.fit(X_train, y_train)
forest_reg.fit(X_train, y_train)

# Make predictions
linear_pred = linear_reg.predict(X_train)
tree_pred = tree_reg.predict(X_train)
forest_pred = forest_reg.predict(X_train)

# Evaluate models
linear_mse = mean_squared_error(y_train, linear_pred)
linear_r2 = r2_score(y_train, linear_pred)

tree_mse = mean_squared_error(y_train, tree_pred)
tree_r2 = r2_score(y_train, tree_pred)

forest_mse = mean_squared_error(y_train, forest_pred)
forest_r2 = r2_score(y_train, forest_pred)

print(f"Linear Regression - Training MSE: {linear_mse:.4f}, R2: {linear_r2:.4f}")
print(f"Decision Tree Regression - Training MSE: {tree_mse:.4f}, R2: {tree_r2:.4f}")
print(f"Random Forest Regression - Training MSE: {forest_mse:.4f}, R2: {forest_r2:.4f}")

"""Optimize the hyperparameters of the three regression models using GridSearchCV and cross-validation"""

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, r2_score
from sklearn.metrics import mean_squared_error

# Define parameter grids (same as before)
param_grid_linear = {}

param_grid_tree = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

param_grid_forest = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

# Use a lambda function to create a scorer
scoring = make_scorer(lambda y_true, y_pred: -mean_squared_error(y_true, y_pred))

# Initialize and fit GridSearchCV objects (same as before)
grid_search_linear = GridSearchCV(linear_reg, param_grid_linear, cv=5, scoring=scoring)
grid_search_tree = GridSearchCV(tree_reg, param_grid_tree, cv=5, scoring=scoring)
grid_search_forest = GridSearchCV(forest_reg, param_grid_forest, cv=5, scoring=scoring)

grid_search_linear.fit(X_train, y_train)
grid_search_tree.fit(X_train, y_train)
grid_search_forest.fit(X_train, y_train)

# Print results (same as before)
print("Linear Regression:")
print("Best Hyperparameters:", grid_search_linear.best_params_)
print("Best Score (neg_mean_squared_error):", grid_search_linear.best_score_)

print("\nDecision Tree Regression:")
print("Best Hyperparameters:", grid_search_tree.best_params_)
print("Best Score (neg_mean_squared_error):", grid_search_tree.best_score_)

print("\nRandom Forest Regression:")
print("Best Hyperparameters:", grid_search_forest.best_params_)
print("Best Score (neg_mean_squared_error):", grid_search_forest.best_score_)

# Store best models (same as before)
best_linear_reg = grid_search_linear.best_estimator_
best_tree_reg = grid_search_tree.best_estimator_
best_forest_reg = grid_search_forest.best_estimator_

"""Evaluate the performance of the best models on the test set by predicting on X_test and calculating MSE and R2 scores"""

from sklearn.metrics import mean_squared_error, r2_score

# Predict on the test set
linear_pred_test = best_linear_reg.predict(X_test)
tree_pred_test = best_tree_reg.predict(X_test)
forest_pred_test = best_forest_reg.predict(X_test)

# Evaluate models on the test set
linear_mse_test = mean_squared_error(y_test, linear_pred_test)
linear_r2_test = r2_score(y_test, linear_pred_test)

tree_mse_test = mean_squared_error(y_test, tree_pred_test)
tree_r2_test = r2_score(y_test, tree_pred_test)

forest_mse_test = mean_squared_error(y_test, forest_pred_test)
forest_r2_test = r2_score(y_test, forest_pred_test)

print(f"Linear Regression - Test MSE: {linear_mse_test:.4f}, R2: {linear_r2_test:.4f}")
print(f"Decision Tree Regression - Test MSE: {tree_mse_test:.4f}, R2: {tree_r2_test:.4f}")
print(f"Random Forest Regression - Test MSE: {forest_mse_test:.4f}, R2: {forest_r2_test:.4f}")

"""Visualize the performance of the three regression models and explore key relationships in the data, as per the user's request"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd

# 1. Scatter plots of predicted vs. actual GPA
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.scatter(y_test, linear_pred_test, alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # Perfect prediction line
plt.xlabel('Actual GPA')
plt.ylabel('Predicted GPA')
plt.title('Linear Regression')

plt.subplot(1, 3, 2)
plt.scatter(y_test, tree_pred_test, alpha=0.5, color='orange')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # Perfect prediction line
plt.xlabel('Actual GPA')
plt.ylabel('Predicted GPA')
plt.title('Decision Tree Regression')

plt.subplot(1, 3, 3)
plt.scatter(y_test, forest_pred_test, alpha=0.5, color='green')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # Perfect prediction line
plt.xlabel('Actual GPA')
plt.ylabel('Predicted GPA')
plt.title('Random Forest Regression')

plt.tight_layout()
plt.show()


# 2. Bar chart comparing MSE and R-squared
mse_values = [linear_mse_test, tree_mse_test, forest_mse_test]
r2_values = [linear_r2_test, tree_r2_test, forest_r2_test]
models = ['Linear', 'Decision Tree', 'Random Forest']
x = np.arange(len(models))
width = 0.35

plt.figure(figsize=(10, 6))
plt.bar(x - width / 2, mse_values, width, label='MSE', color='skyblue')
plt.bar(x + width / 2, r2_values, width, label='R-squared', color='lightcoral')
plt.xticks(x, models)
plt.xlabel("Model")
plt.ylabel("Value")
plt.title("Model Performance Comparison")
plt.legend()
plt.show()


# 3. Feature importances for Random Forest
feature_importances = best_forest_reg.feature_importances_
feature_names = X_train.columns
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis', hue='Importance', legend=False)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importances (Random Forest)')
plt.show()

# 4. Pair plot (manual creation)
important_features = ['GPA', 'StudyTimeWeekly', 'Absences', 'GPA_StudyTime_Interaction']
num_features = len(important_features)
fig, axes = plt.subplots(num_features, num_features, figsize=(15, 15))
fig.suptitle('Pair Plot of Important Features', y=1.02)

for i in range(num_features):
  for j in range(num_features):
    if i == j:
      sns.histplot(df_prepared[important_features[i]], ax=axes[i, j], kde=True)
    else:
      sns.scatterplot(x=df_prepared[important_features[j]], y=df_prepared[important_features[i]], hue=df_prepared['GPA'], palette='husl', ax=axes[i, j], legend=False)

plt.tight_layout()
plt.show()

"""## Summary:

### Data Analysis Key Findings
* **Data Cleaning:** No missing values were found in the initial dataset. Outliers in 'GPA', 'StudyTimeWeekly', and 'Absences' were handled using winsorizing. An inconsistency in the 'GradeClass' column (value '0') was replaced with the mode of that column.
* **Data Preparation:** Categorical features were converted to numerical representations using one-hot encoding (for features with more than two unique values) and label encoding (for binary features). Numerical features were scaled using standardization.
* **Feature Engineering:** New interaction features ('GPA\_StudyTime\_Interaction', 'GPA\_Absences\_Interaction') and polynomial features ('GPA\_Squared', 'StudyTimeWeekly\_Squared') were created to capture potential non-linear relationships.
* **Model Training and Optimization:** Three regression models (Linear Regression, Decision Tree Regression, and Random Forest Regression) were trained and optimized using cross-validation. The Random Forest model showed the best performance in terms of negative mean squared error on the training data.  The Decision Tree achieved perfect training performance (R2 = 1.0), potentially indicating overfitting.
* **Model Evaluation:** The optimized Random Forest model exhibited the best generalization performance on the test set, with the lowest MSE (0.0105) and highest R2 score (0.9894). Linear Regression and Decision Tree Regression showed decent performance as well.

1. Data Preparation:

Format: The input data needs to be in the same format as the data used to train the models. This means it should have the same columns (features) and data types as the df_prepared DataFrame.
Categorical Features: If you have categorical features (e.g., Gender, Parental Education), make sure they are encoded in the same way as in the training data. You can use the same OneHotEncoder and LabelEncoder objects that were used during data preparation to ensure consistent encoding.
Numerical Features: If you have numerical features (e.g., Age, StudyTimeWeekly), make sure they are scaled using the same StandardScaler object that was used during data preparation. This ensures that the input data is on the same scale as the training data.
2. Inputting Data:

Create a DataFrame: Create a pandas DataFrame with your new data, ensuring that the columns match the features used in the training data.
Example:

new_data = pd.DataFrame({
    'Age': [16],
    'StudyTimeWeekly': [10],
    'Absences': [2],
    'Gender': ['Male'],  # Assuming you have the same categories as in training data
    'ParentalEducation': ['Bachelor\'s degree'],
})

3. Feature Engineering:

If you engineered new features during the training process (e.g., interaction terms, polynomial terms), you need to create the same features for the new input data as well. Use the same logic and formulas that were used during feature engineering.
Example:

new_data['GPA_StudyTime_Interaction'] = new_data['GPA'] * new_data['StudyTimeWeekly']

4. Encoding and Scaling:

Apply the same encoding and scaling techniques that were used during data preparation to the new input data.
Example:

# Encoding categorical features (example using LabelEncoder for Gender)
new_data['Gender'] = le.transform(new_data['Gender'])

# Scaling numerical features
new_data[['Age', 'StudyTimeWeekly', 'Absences']] = scaler.transform(new_data[['Age', 'StudyTimeWeekly', 'Absences']])

5. Making Predictions:

Use the trained model to make predictions on the prepared input data.
Example:

predictions = best_forest_reg.predict(new_data)  # Using the best Random Forest model

Important Considerations:

Model Selection: Choose the best-performing model based on your evaluation results from the project.
Data Quality: Ensure the quality and consistency of the input data to get reliable predictions.
Interpretation: Remember that the predictions are based on the patterns learned by the model from the training data. Be cautious when interpreting the results and consider the limitations of the model.

some ways to enhance this project for greater efficiency and effectiveness:

1. Data Augmentation:

Reasoning: The current dataset might not be large enough to capture the full complexity of student performance. Augmenting the data can improve model generalization and robustness.
Methods: Consider techniques like SMOTE (Synthetic Minority Over-sampling Technique) or ADASYN (Adaptive Synthetic Sampling Approach) to generate synthetic data points, especially if the dataset has class imbalance.
2. Feature Selection:

Reasoning: Including irrelevant or redundant features can negatively impact model performance and interpretability.
Methods: Apply feature selection techniques like Recursive Feature Elimination (RFE), feature importance analysis from tree-based models, or LASSO regularization to identify the most important features.
3. Hyperparameter Tuning:

Reasoning: The current hyperparameter optimization might not have explored the full range of possible values.
Methods: Use more extensive hyperparameter search techniques like Bayesian optimization or evolutionary algorithms to find better hyperparameter settings.
4. Advanced Model Architectures:

Reasoning: Explore more advanced regression models like neural networks, support vector regression, or gradient boosting machines to potentially improve prediction accuracy.
5. Incorporating External Data:

Reasoning: Student performance is often influenced by external factors not captured in the current dataset.
Methods: Consider integrating data from other sources, such as school demographics, socioeconomic indicators, or student engagement metrics.
6. Real-time Monitoring and Feedback:

Reasoning: Continuously monitor model performance and gather feedback from users to identify areas for improvement.
Methods: Implement a system to track model predictions, compare them with actual outcomes, and collect user feedback. Use this information to retrain and update the model periodically.
7. Deployment and User Interface:

Reasoning: Make the model accessible to users through a user-friendly interface.
Methods: Develop a web application or integrate the model into existing educational platforms to allow users to input data and receive predictions easily.
8. Interpretability and Explainability:

Reasoning: Understanding how the model makes predictions is crucial for trust and actionable insights.
Methods: Use techniques like SHAP (SHapley Additive exPlanations) or LIME (Local Interpretable Model-agnostic Explanations) to explain model predictions in a way that is understandable to users.
9. Addressing Ethical Considerations:

Reasoning: Ensure that the model is used ethically and does not perpetuate biases or discrimination.
Methods: Carefully consider the potential impact of the model on different student groups and implement safeguards to prevent unfair outcomes.
By incorporating these enhancements, the project can achieve greater efficiency in terms of model development and deployment, and greater effectiveness in terms of prediction accuracy and actionable insights.

A big thanks to 3MTT, Darey.io and the Federal Republic of Nigeria for the opportunity given to me in this pathway, data science.
I also appreciate my able and committed facilitator in person of Hannah Igboke, your patience is remarkable. thank you all for your investment in my life. i dedicate this project to you all.
"""